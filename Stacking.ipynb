{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BfyGsMOvMWMT"
   },
   "source": [
    "In this assignment we implement an ensemble method: Stacking.\n",
    "We are going to train a neural network and a decision tree first, and then use their predictions as input to a second classifier: Logistic Regression.\n",
    "\n",
    "We start as usual with installing some software.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Sy9ekTGLYbSO",
    "outputId": "334bf5fd-d613-4a1a-990d-40dbcdbdcbc0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'apt-get' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "'ln' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "'ln' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn==1.2.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (1.2.2)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\user\\anaconda3\\lib\\site-packages (from scikit-learn==1.2.2) (1.22.4)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from scikit-learn==1.2.2) (2.2.0)\n",
      "Requirement already satisfied: scipy>=1.3.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from scikit-learn==1.2.2) (1.7.3)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from scikit-learn==1.2.2) (1.3.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# SETUP\n",
    "# install python at version 3.10\n",
    "!apt-get install python3.10\n",
    "\n",
    "# update symbolic links to the newly installed python version\n",
    "!ln -sf /usr/bin/python3.10 /usr/bin/python\n",
    "!ln -sf /usr/bin/python3.10 /usr/bin/python3\n",
    "\n",
    "# install scikit-learn 1.2.2\n",
    "%pip install scikit-learn==1.2.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2_PISpyC9r-b"
   },
   "source": [
    "Next we create a corpus and extract a train, a validation and a test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iYJP_3XLNtg3",
    "outputId": "4c8912ee-e48d-40ca-eb81-5b6b73b44f2b"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[1;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrandom\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m make_blobs\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrandom_seed\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m set_random_seed\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from sklearn.datasets import make_blobs\n",
    "from tensorflow.python.framework.random_seed import set_random_seed\n",
    "from keras import initializers\n",
    "from matplotlib import pyplot\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import SGD\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.layers import Dense, Input\n",
    "from keras.utils import to_categorical\n",
    "from tensorflow.python.framework.random_seed import set_random_seed\n",
    "\n",
    "X, y = make_blobs(n_samples=1100, centers=3, n_features=2, cluster_std=2, random_state=2)\n",
    "trainX, valtestX, trainy, valtesty = train_test_split(X, y, train_size=0.1, shuffle=False)\n",
    "valX, testX, valy, testy = train_test_split(valtestX, valtesty, train_size=0.112, shuffle=False)\n",
    "trainy_cat, valy_cat, testy_cat = to_categorical(trainy), to_categorical(valy), to_categorical(testy)\n",
    "\n",
    "print(trainX.shape, valX.shape, testX.shape)\n",
    "\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "set_random_seed(42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TCPq9DqgGLgn"
   },
   "source": [
    "**Exercise 2.1**\n",
    "\n",
    "Let's train a Neural Network on the training set trainX.\n",
    "The network uses:\n",
    "\n",
    "*   an input layer, an hidden layer of dimension 25 with RELU activation function, an output layer of dimension 3 with softmax activation\n",
    "*   categorical cross entropy as loss\n",
    "*   adam as optimizer\n",
    "*   valX as validation set. The option to the command fit for doing this is \"validation_data=(valX, valy_cat)\"\n",
    "*   train for 500 epochs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5l9EJgkR74vZ",
    "outputId": "bd6407ed-c1db-4c82-ec29-ba1b5349455b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "4/4 [==============================] - 1s 71ms/step - loss: 1.0374 - accuracy: 0.4727 - val_loss: 1.0729 - val_accuracy: 0.4636\n",
      "Epoch 2/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 1.0048 - accuracy: 0.4727 - val_loss: 1.0404 - val_accuracy: 0.4636\n",
      "Epoch 3/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.9770 - accuracy: 0.4727 - val_loss: 1.0078 - val_accuracy: 0.4636\n",
      "Epoch 4/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.9496 - accuracy: 0.4727 - val_loss: 0.9781 - val_accuracy: 0.4636\n",
      "Epoch 5/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.9225 - accuracy: 0.4909 - val_loss: 0.9520 - val_accuracy: 0.4727\n",
      "Epoch 6/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.9004 - accuracy: 0.4909 - val_loss: 0.9279 - val_accuracy: 0.4818\n",
      "Epoch 7/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.8796 - accuracy: 0.5091 - val_loss: 0.9061 - val_accuracy: 0.4727\n",
      "Epoch 8/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.8597 - accuracy: 0.5091 - val_loss: 0.8862 - val_accuracy: 0.4727\n",
      "Epoch 9/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.8409 - accuracy: 0.5091 - val_loss: 0.8686 - val_accuracy: 0.4727\n",
      "Epoch 10/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.8251 - accuracy: 0.5273 - val_loss: 0.8520 - val_accuracy: 0.4818\n",
      "Epoch 11/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.8121 - accuracy: 0.5727 - val_loss: 0.8374 - val_accuracy: 0.4818\n",
      "Epoch 12/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.7978 - accuracy: 0.5909 - val_loss: 0.8259 - val_accuracy: 0.4909\n",
      "Epoch 13/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.7854 - accuracy: 0.6182 - val_loss: 0.8158 - val_accuracy: 0.5273\n",
      "Epoch 14/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.7750 - accuracy: 0.6273 - val_loss: 0.8071 - val_accuracy: 0.5545\n",
      "Epoch 15/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.7640 - accuracy: 0.6364 - val_loss: 0.7996 - val_accuracy: 0.5545\n",
      "Epoch 16/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7545 - accuracy: 0.6364 - val_loss: 0.7928 - val_accuracy: 0.5545\n",
      "Epoch 17/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.7455 - accuracy: 0.6364 - val_loss: 0.7866 - val_accuracy: 0.5636\n",
      "Epoch 18/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7371 - accuracy: 0.6545 - val_loss: 0.7791 - val_accuracy: 0.5727\n",
      "Epoch 19/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.7287 - accuracy: 0.6545 - val_loss: 0.7727 - val_accuracy: 0.6091\n",
      "Epoch 20/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.7208 - accuracy: 0.6545 - val_loss: 0.7666 - val_accuracy: 0.6091\n",
      "Epoch 21/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7143 - accuracy: 0.6727 - val_loss: 0.7602 - val_accuracy: 0.6091\n",
      "Epoch 22/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.7068 - accuracy: 0.6818 - val_loss: 0.7541 - val_accuracy: 0.6091\n",
      "Epoch 23/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.7006 - accuracy: 0.6909 - val_loss: 0.7486 - val_accuracy: 0.6091\n",
      "Epoch 24/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.6939 - accuracy: 0.6818 - val_loss: 0.7440 - val_accuracy: 0.6091\n",
      "Epoch 25/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.6879 - accuracy: 0.7000 - val_loss: 0.7386 - val_accuracy: 0.6182\n",
      "Epoch 26/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.6821 - accuracy: 0.7091 - val_loss: 0.7343 - val_accuracy: 0.6182\n",
      "Epoch 27/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.6771 - accuracy: 0.7091 - val_loss: 0.7306 - val_accuracy: 0.6182\n",
      "Epoch 28/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.6720 - accuracy: 0.6909 - val_loss: 0.7273 - val_accuracy: 0.6182\n",
      "Epoch 29/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.6663 - accuracy: 0.6909 - val_loss: 0.7246 - val_accuracy: 0.6182\n",
      "Epoch 30/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.6620 - accuracy: 0.6909 - val_loss: 0.7225 - val_accuracy: 0.6182\n",
      "Epoch 31/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.6569 - accuracy: 0.7000 - val_loss: 0.7198 - val_accuracy: 0.6182\n",
      "Epoch 32/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.6527 - accuracy: 0.7000 - val_loss: 0.7181 - val_accuracy: 0.6182\n",
      "Epoch 33/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.6481 - accuracy: 0.6909 - val_loss: 0.7160 - val_accuracy: 0.6182\n",
      "Epoch 34/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.6443 - accuracy: 0.7000 - val_loss: 0.7138 - val_accuracy: 0.6182\n",
      "Epoch 35/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.6403 - accuracy: 0.7000 - val_loss: 0.7115 - val_accuracy: 0.6182\n",
      "Epoch 36/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.6365 - accuracy: 0.7091 - val_loss: 0.7103 - val_accuracy: 0.6091\n",
      "Epoch 37/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.6328 - accuracy: 0.7000 - val_loss: 0.7075 - val_accuracy: 0.6182\n",
      "Epoch 38/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.6292 - accuracy: 0.7091 - val_loss: 0.7032 - val_accuracy: 0.6273\n",
      "Epoch 39/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.6255 - accuracy: 0.7091 - val_loss: 0.6988 - val_accuracy: 0.6364\n",
      "Epoch 40/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.6221 - accuracy: 0.7091 - val_loss: 0.6952 - val_accuracy: 0.6455\n",
      "Epoch 41/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.6186 - accuracy: 0.7091 - val_loss: 0.6929 - val_accuracy: 0.6545\n",
      "Epoch 42/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.6155 - accuracy: 0.7091 - val_loss: 0.6906 - val_accuracy: 0.6545\n",
      "Epoch 43/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.6124 - accuracy: 0.7091 - val_loss: 0.6871 - val_accuracy: 0.6545\n",
      "Epoch 44/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.6091 - accuracy: 0.7091 - val_loss: 0.6847 - val_accuracy: 0.6636\n",
      "Epoch 45/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.6065 - accuracy: 0.7091 - val_loss: 0.6816 - val_accuracy: 0.6545\n",
      "Epoch 46/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.6034 - accuracy: 0.7091 - val_loss: 0.6787 - val_accuracy: 0.6545\n",
      "Epoch 47/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.6004 - accuracy: 0.7091 - val_loss: 0.6767 - val_accuracy: 0.6545\n",
      "Epoch 48/500\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.5976 - accuracy: 0.7091 - val_loss: 0.6748 - val_accuracy: 0.6545\n",
      "Epoch 49/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.5949 - accuracy: 0.7091 - val_loss: 0.6725 - val_accuracy: 0.6545\n",
      "Epoch 50/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.5923 - accuracy: 0.7091 - val_loss: 0.6715 - val_accuracy: 0.6636\n",
      "Epoch 51/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.5898 - accuracy: 0.7091 - val_loss: 0.6692 - val_accuracy: 0.6818\n",
      "Epoch 52/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.5869 - accuracy: 0.7091 - val_loss: 0.6673 - val_accuracy: 0.6818\n",
      "Epoch 53/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.5846 - accuracy: 0.7182 - val_loss: 0.6655 - val_accuracy: 0.6818\n",
      "Epoch 54/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.5818 - accuracy: 0.7182 - val_loss: 0.6628 - val_accuracy: 0.6818\n",
      "Epoch 55/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.5792 - accuracy: 0.7182 - val_loss: 0.6607 - val_accuracy: 0.6909\n",
      "Epoch 56/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.5767 - accuracy: 0.7182 - val_loss: 0.6578 - val_accuracy: 0.6909\n",
      "Epoch 57/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.5741 - accuracy: 0.7182 - val_loss: 0.6544 - val_accuracy: 0.6909\n",
      "Epoch 58/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.5714 - accuracy: 0.7182 - val_loss: 0.6514 - val_accuracy: 0.6909\n",
      "Epoch 59/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.5689 - accuracy: 0.7182 - val_loss: 0.6483 - val_accuracy: 0.6818\n",
      "Epoch 60/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.5665 - accuracy: 0.7182 - val_loss: 0.6440 - val_accuracy: 0.6818\n",
      "Epoch 61/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.5644 - accuracy: 0.7182 - val_loss: 0.6403 - val_accuracy: 0.6909\n",
      "Epoch 62/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.5628 - accuracy: 0.7182 - val_loss: 0.6371 - val_accuracy: 0.6909\n",
      "Epoch 63/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.5611 - accuracy: 0.7273 - val_loss: 0.6346 - val_accuracy: 0.7000\n",
      "Epoch 64/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.5587 - accuracy: 0.7364 - val_loss: 0.6343 - val_accuracy: 0.7000\n",
      "Epoch 65/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.5566 - accuracy: 0.7273 - val_loss: 0.6337 - val_accuracy: 0.7091\n",
      "Epoch 66/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.5543 - accuracy: 0.7364 - val_loss: 0.6314 - val_accuracy: 0.7091\n",
      "Epoch 67/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.5520 - accuracy: 0.7545 - val_loss: 0.6292 - val_accuracy: 0.7091\n",
      "Epoch 68/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.5497 - accuracy: 0.7545 - val_loss: 0.6288 - val_accuracy: 0.7091\n",
      "Epoch 69/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.5473 - accuracy: 0.7455 - val_loss: 0.6283 - val_accuracy: 0.7091\n",
      "Epoch 70/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.5454 - accuracy: 0.7455 - val_loss: 0.6279 - val_accuracy: 0.7091\n",
      "Epoch 71/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.5427 - accuracy: 0.7364 - val_loss: 0.6257 - val_accuracy: 0.7091\n",
      "Epoch 72/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.5405 - accuracy: 0.7455 - val_loss: 0.6244 - val_accuracy: 0.7182\n",
      "Epoch 73/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.5383 - accuracy: 0.7455 - val_loss: 0.6228 - val_accuracy: 0.7182\n",
      "Epoch 74/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.5363 - accuracy: 0.7455 - val_loss: 0.6207 - val_accuracy: 0.7091\n",
      "Epoch 75/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.5340 - accuracy: 0.7455 - val_loss: 0.6182 - val_accuracy: 0.7091\n",
      "Epoch 76/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.5320 - accuracy: 0.7455 - val_loss: 0.6158 - val_accuracy: 0.7091\n",
      "Epoch 77/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.5303 - accuracy: 0.7545 - val_loss: 0.6136 - val_accuracy: 0.7091\n",
      "Epoch 78/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.5279 - accuracy: 0.7455 - val_loss: 0.6128 - val_accuracy: 0.7091\n",
      "Epoch 79/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.5265 - accuracy: 0.7455 - val_loss: 0.6138 - val_accuracy: 0.7182\n",
      "Epoch 80/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.5242 - accuracy: 0.7636 - val_loss: 0.6121 - val_accuracy: 0.7182\n",
      "Epoch 81/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.5217 - accuracy: 0.7636 - val_loss: 0.6096 - val_accuracy: 0.7182\n",
      "Epoch 82/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.5196 - accuracy: 0.7636 - val_loss: 0.6075 - val_accuracy: 0.7182\n",
      "Epoch 83/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.5175 - accuracy: 0.7636 - val_loss: 0.6050 - val_accuracy: 0.7182\n",
      "Epoch 84/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.5155 - accuracy: 0.7636 - val_loss: 0.6031 - val_accuracy: 0.7182\n",
      "Epoch 85/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.5134 - accuracy: 0.7545 - val_loss: 0.6001 - val_accuracy: 0.7273\n",
      "Epoch 86/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.5116 - accuracy: 0.7636 - val_loss: 0.5983 - val_accuracy: 0.7364\n",
      "Epoch 87/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.5094 - accuracy: 0.7636 - val_loss: 0.5955 - val_accuracy: 0.7364\n",
      "Epoch 88/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.5075 - accuracy: 0.7636 - val_loss: 0.5927 - val_accuracy: 0.7364\n",
      "Epoch 89/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.5059 - accuracy: 0.7727 - val_loss: 0.5908 - val_accuracy: 0.7364\n",
      "Epoch 90/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.5038 - accuracy: 0.7727 - val_loss: 0.5892 - val_accuracy: 0.7364\n",
      "Epoch 91/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.5019 - accuracy: 0.7727 - val_loss: 0.5884 - val_accuracy: 0.7364\n",
      "Epoch 92/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.4999 - accuracy: 0.7636 - val_loss: 0.5869 - val_accuracy: 0.7364\n",
      "Epoch 93/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.4980 - accuracy: 0.7636 - val_loss: 0.5848 - val_accuracy: 0.7364\n",
      "Epoch 94/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.4961 - accuracy: 0.7636 - val_loss: 0.5830 - val_accuracy: 0.7364\n",
      "Epoch 95/500\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.4942 - accuracy: 0.7636 - val_loss: 0.5828 - val_accuracy: 0.7364\n",
      "Epoch 96/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.4923 - accuracy: 0.7636 - val_loss: 0.5815 - val_accuracy: 0.7364\n",
      "Epoch 97/500\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.4903 - accuracy: 0.7636 - val_loss: 0.5797 - val_accuracy: 0.7364\n",
      "Epoch 98/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4883 - accuracy: 0.7636 - val_loss: 0.5787 - val_accuracy: 0.7455\n",
      "Epoch 99/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.4861 - accuracy: 0.7636 - val_loss: 0.5772 - val_accuracy: 0.7455\n",
      "Epoch 100/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.4845 - accuracy: 0.7727 - val_loss: 0.5749 - val_accuracy: 0.7455\n",
      "Epoch 101/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4824 - accuracy: 0.7727 - val_loss: 0.5720 - val_accuracy: 0.7545\n",
      "Epoch 102/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4806 - accuracy: 0.7909 - val_loss: 0.5691 - val_accuracy: 0.7545\n",
      "Epoch 103/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.4793 - accuracy: 0.8000 - val_loss: 0.5678 - val_accuracy: 0.7545\n",
      "Epoch 104/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.4775 - accuracy: 0.8000 - val_loss: 0.5652 - val_accuracy: 0.7545\n",
      "Epoch 105/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.4756 - accuracy: 0.8000 - val_loss: 0.5648 - val_accuracy: 0.7545\n",
      "Epoch 106/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4734 - accuracy: 0.7909 - val_loss: 0.5639 - val_accuracy: 0.7545\n",
      "Epoch 107/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.4718 - accuracy: 0.8000 - val_loss: 0.5644 - val_accuracy: 0.7636\n",
      "Epoch 108/500\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.4697 - accuracy: 0.8000 - val_loss: 0.5621 - val_accuracy: 0.7636\n",
      "Epoch 109/500\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.4680 - accuracy: 0.8000 - val_loss: 0.5606 - val_accuracy: 0.7636\n",
      "Epoch 110/500\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.4666 - accuracy: 0.8091 - val_loss: 0.5587 - val_accuracy: 0.7636\n",
      "Epoch 111/500\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.4650 - accuracy: 0.8000 - val_loss: 0.5539 - val_accuracy: 0.7636\n",
      "Epoch 112/500\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.4629 - accuracy: 0.8000 - val_loss: 0.5518 - val_accuracy: 0.7727\n",
      "Epoch 113/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.4611 - accuracy: 0.8000 - val_loss: 0.5506 - val_accuracy: 0.7727\n",
      "Epoch 114/500\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.4596 - accuracy: 0.8000 - val_loss: 0.5497 - val_accuracy: 0.7727\n",
      "Epoch 115/500\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.4574 - accuracy: 0.8000 - val_loss: 0.5481 - val_accuracy: 0.7727\n",
      "Epoch 116/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.4559 - accuracy: 0.8091 - val_loss: 0.5467 - val_accuracy: 0.7727\n",
      "Epoch 117/500\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.4543 - accuracy: 0.8091 - val_loss: 0.5454 - val_accuracy: 0.7727\n",
      "Epoch 118/500\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.4530 - accuracy: 0.8182 - val_loss: 0.5445 - val_accuracy: 0.7727\n",
      "Epoch 119/500\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.4514 - accuracy: 0.8182 - val_loss: 0.5417 - val_accuracy: 0.7727\n",
      "Epoch 120/500\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.4496 - accuracy: 0.8182 - val_loss: 0.5407 - val_accuracy: 0.7818\n",
      "Epoch 121/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.4481 - accuracy: 0.8182 - val_loss: 0.5392 - val_accuracy: 0.7818\n",
      "Epoch 122/500\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.4465 - accuracy: 0.8182 - val_loss: 0.5382 - val_accuracy: 0.7909\n",
      "Epoch 123/500\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.4452 - accuracy: 0.8182 - val_loss: 0.5366 - val_accuracy: 0.7909\n",
      "Epoch 124/500\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.4436 - accuracy: 0.8182 - val_loss: 0.5339 - val_accuracy: 0.7909\n",
      "Epoch 125/500\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.4424 - accuracy: 0.8182 - val_loss: 0.5322 - val_accuracy: 0.7909\n",
      "Epoch 126/500\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.4410 - accuracy: 0.8182 - val_loss: 0.5316 - val_accuracy: 0.7909\n",
      "Epoch 127/500\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.4399 - accuracy: 0.8273 - val_loss: 0.5313 - val_accuracy: 0.7909\n",
      "Epoch 128/500\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.4383 - accuracy: 0.8182 - val_loss: 0.5309 - val_accuracy: 0.7909\n",
      "Epoch 129/500\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.4372 - accuracy: 0.8182 - val_loss: 0.5289 - val_accuracy: 0.7909\n",
      "Epoch 130/500\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.4363 - accuracy: 0.8273 - val_loss: 0.5270 - val_accuracy: 0.7909\n",
      "Epoch 131/500\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.4345 - accuracy: 0.8273 - val_loss: 0.5264 - val_accuracy: 0.7909\n",
      "Epoch 132/500\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.4336 - accuracy: 0.8273 - val_loss: 0.5261 - val_accuracy: 0.7909\n",
      "Epoch 133/500\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.4322 - accuracy: 0.8273 - val_loss: 0.5259 - val_accuracy: 0.7909\n",
      "Epoch 134/500\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.4310 - accuracy: 0.8182 - val_loss: 0.5261 - val_accuracy: 0.7909\n",
      "Epoch 135/500\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.4299 - accuracy: 0.8182 - val_loss: 0.5256 - val_accuracy: 0.7909\n",
      "Epoch 136/500\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.4289 - accuracy: 0.8182 - val_loss: 0.5250 - val_accuracy: 0.7909\n",
      "Epoch 137/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.4271 - accuracy: 0.8182 - val_loss: 0.5223 - val_accuracy: 0.7909\n",
      "Epoch 138/500\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.4260 - accuracy: 0.8273 - val_loss: 0.5184 - val_accuracy: 0.7909\n",
      "Epoch 139/500\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.4255 - accuracy: 0.8182 - val_loss: 0.5166 - val_accuracy: 0.7909\n",
      "Epoch 140/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.4246 - accuracy: 0.8182 - val_loss: 0.5155 - val_accuracy: 0.7909\n",
      "Epoch 141/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.4237 - accuracy: 0.8273 - val_loss: 0.5148 - val_accuracy: 0.7909\n",
      "Epoch 142/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.4228 - accuracy: 0.8182 - val_loss: 0.5148 - val_accuracy: 0.7909\n",
      "Epoch 143/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.4212 - accuracy: 0.8273 - val_loss: 0.5166 - val_accuracy: 0.7909\n",
      "Epoch 144/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.4197 - accuracy: 0.8182 - val_loss: 0.5192 - val_accuracy: 0.7909\n",
      "Epoch 145/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.4190 - accuracy: 0.8182 - val_loss: 0.5209 - val_accuracy: 0.7909\n",
      "Epoch 146/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.4177 - accuracy: 0.8182 - val_loss: 0.5200 - val_accuracy: 0.7909\n",
      "Epoch 147/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.4166 - accuracy: 0.8182 - val_loss: 0.5181 - val_accuracy: 0.7909\n",
      "Epoch 148/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4153 - accuracy: 0.8273 - val_loss: 0.5156 - val_accuracy: 0.7909\n",
      "Epoch 149/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.4145 - accuracy: 0.8273 - val_loss: 0.5147 - val_accuracy: 0.7909\n",
      "Epoch 150/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.4134 - accuracy: 0.8182 - val_loss: 0.5139 - val_accuracy: 0.7909\n",
      "Epoch 151/500\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.4125 - accuracy: 0.8273 - val_loss: 0.5129 - val_accuracy: 0.7909\n",
      "Epoch 152/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4117 - accuracy: 0.8273 - val_loss: 0.5134 - val_accuracy: 0.7909\n",
      "Epoch 153/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.4109 - accuracy: 0.8273 - val_loss: 0.5119 - val_accuracy: 0.7909\n",
      "Epoch 154/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.4095 - accuracy: 0.8182 - val_loss: 0.5092 - val_accuracy: 0.7909\n",
      "Epoch 155/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.4101 - accuracy: 0.8182 - val_loss: 0.5063 - val_accuracy: 0.7909\n",
      "Epoch 156/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.4092 - accuracy: 0.8091 - val_loss: 0.5050 - val_accuracy: 0.7909\n",
      "Epoch 157/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4077 - accuracy: 0.8273 - val_loss: 0.5066 - val_accuracy: 0.7909\n",
      "Epoch 158/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4064 - accuracy: 0.8182 - val_loss: 0.5090 - val_accuracy: 0.7909\n",
      "Epoch 159/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.4054 - accuracy: 0.8273 - val_loss: 0.5109 - val_accuracy: 0.7909\n",
      "Epoch 160/500\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.4048 - accuracy: 0.8182 - val_loss: 0.5109 - val_accuracy: 0.7818\n",
      "Epoch 161/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.4041 - accuracy: 0.8182 - val_loss: 0.5079 - val_accuracy: 0.7909\n",
      "Epoch 162/500\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.4030 - accuracy: 0.8364 - val_loss: 0.5063 - val_accuracy: 0.7909\n",
      "Epoch 163/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.4022 - accuracy: 0.8273 - val_loss: 0.5055 - val_accuracy: 0.7909\n",
      "Epoch 164/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.4009 - accuracy: 0.8182 - val_loss: 0.5039 - val_accuracy: 0.7909\n",
      "Epoch 165/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4008 - accuracy: 0.8182 - val_loss: 0.5013 - val_accuracy: 0.7909\n",
      "Epoch 166/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.3995 - accuracy: 0.8182 - val_loss: 0.4998 - val_accuracy: 0.7909\n",
      "Epoch 167/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.3987 - accuracy: 0.8182 - val_loss: 0.4982 - val_accuracy: 0.7909\n",
      "Epoch 168/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.3978 - accuracy: 0.8182 - val_loss: 0.4976 - val_accuracy: 0.7909\n",
      "Epoch 169/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.3973 - accuracy: 0.8273 - val_loss: 0.4962 - val_accuracy: 0.7909\n",
      "Epoch 170/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.3961 - accuracy: 0.8273 - val_loss: 0.4965 - val_accuracy: 0.7909\n",
      "Epoch 171/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.3952 - accuracy: 0.8182 - val_loss: 0.4977 - val_accuracy: 0.7909\n",
      "Epoch 172/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.3941 - accuracy: 0.8182 - val_loss: 0.4977 - val_accuracy: 0.7909\n",
      "Epoch 173/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.3935 - accuracy: 0.8182 - val_loss: 0.4977 - val_accuracy: 0.7909\n",
      "Epoch 174/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.3930 - accuracy: 0.8182 - val_loss: 0.4964 - val_accuracy: 0.7909\n",
      "Epoch 175/500\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.3920 - accuracy: 0.8182 - val_loss: 0.4940 - val_accuracy: 0.7909\n",
      "Epoch 176/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.3915 - accuracy: 0.8182 - val_loss: 0.4913 - val_accuracy: 0.7909\n",
      "Epoch 177/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.3910 - accuracy: 0.8364 - val_loss: 0.4891 - val_accuracy: 0.7909\n",
      "Epoch 178/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3902 - accuracy: 0.8273 - val_loss: 0.4889 - val_accuracy: 0.7909\n",
      "Epoch 179/500\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.3894 - accuracy: 0.8364 - val_loss: 0.4897 - val_accuracy: 0.7909\n",
      "Epoch 180/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.3884 - accuracy: 0.8364 - val_loss: 0.4910 - val_accuracy: 0.7909\n",
      "Epoch 181/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.3877 - accuracy: 0.8273 - val_loss: 0.4934 - val_accuracy: 0.7909\n",
      "Epoch 182/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.3871 - accuracy: 0.8273 - val_loss: 0.4952 - val_accuracy: 0.7909\n",
      "Epoch 183/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.3862 - accuracy: 0.8273 - val_loss: 0.4960 - val_accuracy: 0.7909\n",
      "Epoch 184/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.3856 - accuracy: 0.8364 - val_loss: 0.4976 - val_accuracy: 0.7909\n",
      "Epoch 185/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.3855 - accuracy: 0.8273 - val_loss: 0.5000 - val_accuracy: 0.7727\n",
      "Epoch 186/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.3852 - accuracy: 0.8273 - val_loss: 0.4989 - val_accuracy: 0.7818\n",
      "Epoch 187/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.3846 - accuracy: 0.8182 - val_loss: 0.4979 - val_accuracy: 0.7818\n",
      "Epoch 188/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.3839 - accuracy: 0.8273 - val_loss: 0.4951 - val_accuracy: 0.7909\n",
      "Epoch 189/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.3830 - accuracy: 0.8273 - val_loss: 0.4923 - val_accuracy: 0.7818\n",
      "Epoch 190/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.3818 - accuracy: 0.8273 - val_loss: 0.4905 - val_accuracy: 0.7818\n",
      "Epoch 191/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.3812 - accuracy: 0.8273 - val_loss: 0.4906 - val_accuracy: 0.7818\n",
      "Epoch 192/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.3807 - accuracy: 0.8273 - val_loss: 0.4907 - val_accuracy: 0.7818\n",
      "Epoch 193/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.3799 - accuracy: 0.8273 - val_loss: 0.4903 - val_accuracy: 0.7818\n",
      "Epoch 194/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.3793 - accuracy: 0.8273 - val_loss: 0.4901 - val_accuracy: 0.7818\n",
      "Epoch 195/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.3787 - accuracy: 0.8273 - val_loss: 0.4886 - val_accuracy: 0.7909\n",
      "Epoch 196/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.3780 - accuracy: 0.8273 - val_loss: 0.4859 - val_accuracy: 0.7909\n",
      "Epoch 197/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.3776 - accuracy: 0.8364 - val_loss: 0.4830 - val_accuracy: 0.8000\n",
      "Epoch 198/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.3770 - accuracy: 0.8364 - val_loss: 0.4823 - val_accuracy: 0.8000\n",
      "Epoch 199/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.3769 - accuracy: 0.8364 - val_loss: 0.4798 - val_accuracy: 0.8000\n",
      "Epoch 200/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.3770 - accuracy: 0.8273 - val_loss: 0.4786 - val_accuracy: 0.8000\n",
      "Epoch 201/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.3757 - accuracy: 0.8273 - val_loss: 0.4790 - val_accuracy: 0.8000\n",
      "Epoch 202/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.3749 - accuracy: 0.8364 - val_loss: 0.4788 - val_accuracy: 0.8000\n",
      "Epoch 203/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.3743 - accuracy: 0.8364 - val_loss: 0.4789 - val_accuracy: 0.8000\n",
      "Epoch 204/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.3747 - accuracy: 0.8364 - val_loss: 0.4804 - val_accuracy: 0.8000\n",
      "Epoch 205/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.3735 - accuracy: 0.8364 - val_loss: 0.4799 - val_accuracy: 0.8000\n",
      "Epoch 206/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.3728 - accuracy: 0.8364 - val_loss: 0.4773 - val_accuracy: 0.8000\n",
      "Epoch 207/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.3721 - accuracy: 0.8364 - val_loss: 0.4756 - val_accuracy: 0.8000\n",
      "Epoch 208/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.3719 - accuracy: 0.8364 - val_loss: 0.4752 - val_accuracy: 0.8000\n",
      "Epoch 209/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.3713 - accuracy: 0.8364 - val_loss: 0.4759 - val_accuracy: 0.8000\n",
      "Epoch 210/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3707 - accuracy: 0.8364 - val_loss: 0.4760 - val_accuracy: 0.8000\n",
      "Epoch 211/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.3700 - accuracy: 0.8364 - val_loss: 0.4766 - val_accuracy: 0.8000\n",
      "Epoch 212/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3697 - accuracy: 0.8364 - val_loss: 0.4782 - val_accuracy: 0.8000\n",
      "Epoch 213/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.3694 - accuracy: 0.8364 - val_loss: 0.4790 - val_accuracy: 0.8000\n",
      "Epoch 214/500\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.3690 - accuracy: 0.8364 - val_loss: 0.4791 - val_accuracy: 0.8000\n",
      "Epoch 215/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.3686 - accuracy: 0.8364 - val_loss: 0.4788 - val_accuracy: 0.8000\n",
      "Epoch 216/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.3680 - accuracy: 0.8364 - val_loss: 0.4775 - val_accuracy: 0.8000\n",
      "Epoch 217/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3677 - accuracy: 0.8364 - val_loss: 0.4745 - val_accuracy: 0.8000\n",
      "Epoch 218/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.3667 - accuracy: 0.8364 - val_loss: 0.4738 - val_accuracy: 0.8000\n",
      "Epoch 219/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.3663 - accuracy: 0.8364 - val_loss: 0.4732 - val_accuracy: 0.8000\n",
      "Epoch 220/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3659 - accuracy: 0.8273 - val_loss: 0.4724 - val_accuracy: 0.8000\n",
      "Epoch 221/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.3656 - accuracy: 0.8273 - val_loss: 0.4713 - val_accuracy: 0.8000\n",
      "Epoch 222/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.3651 - accuracy: 0.8273 - val_loss: 0.4718 - val_accuracy: 0.8000\n",
      "Epoch 223/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.3646 - accuracy: 0.8273 - val_loss: 0.4732 - val_accuracy: 0.8000\n",
      "Epoch 224/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.3639 - accuracy: 0.8273 - val_loss: 0.4738 - val_accuracy: 0.8000\n",
      "Epoch 225/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.3647 - accuracy: 0.8364 - val_loss: 0.4765 - val_accuracy: 0.8000\n",
      "Epoch 226/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.3633 - accuracy: 0.8364 - val_loss: 0.4770 - val_accuracy: 0.8000\n",
      "Epoch 227/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3628 - accuracy: 0.8364 - val_loss: 0.4755 - val_accuracy: 0.8000\n",
      "Epoch 228/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.3626 - accuracy: 0.8364 - val_loss: 0.4736 - val_accuracy: 0.8000\n",
      "Epoch 229/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.3617 - accuracy: 0.8364 - val_loss: 0.4728 - val_accuracy: 0.8000\n",
      "Epoch 230/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.3615 - accuracy: 0.8364 - val_loss: 0.4727 - val_accuracy: 0.8000\n",
      "Epoch 231/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.3610 - accuracy: 0.8273 - val_loss: 0.4742 - val_accuracy: 0.8000\n",
      "Epoch 232/500\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.3605 - accuracy: 0.8364 - val_loss: 0.4751 - val_accuracy: 0.8000\n",
      "Epoch 233/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3602 - accuracy: 0.8364 - val_loss: 0.4757 - val_accuracy: 0.8000\n",
      "Epoch 234/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.3598 - accuracy: 0.8364 - val_loss: 0.4770 - val_accuracy: 0.8000\n",
      "Epoch 235/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.3595 - accuracy: 0.8364 - val_loss: 0.4771 - val_accuracy: 0.8000\n",
      "Epoch 236/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.3590 - accuracy: 0.8364 - val_loss: 0.4784 - val_accuracy: 0.8000\n",
      "Epoch 237/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3589 - accuracy: 0.8364 - val_loss: 0.4787 - val_accuracy: 0.8000\n",
      "Epoch 238/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.3586 - accuracy: 0.8364 - val_loss: 0.4787 - val_accuracy: 0.8000\n",
      "Epoch 239/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.3582 - accuracy: 0.8364 - val_loss: 0.4774 - val_accuracy: 0.8000\n",
      "Epoch 240/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3577 - accuracy: 0.8364 - val_loss: 0.4758 - val_accuracy: 0.8000\n",
      "Epoch 241/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.3572 - accuracy: 0.8364 - val_loss: 0.4747 - val_accuracy: 0.8000\n",
      "Epoch 242/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.3573 - accuracy: 0.8364 - val_loss: 0.4730 - val_accuracy: 0.8000\n",
      "Epoch 243/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.3564 - accuracy: 0.8364 - val_loss: 0.4718 - val_accuracy: 0.8000\n",
      "Epoch 244/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.3561 - accuracy: 0.8273 - val_loss: 0.4711 - val_accuracy: 0.8000\n",
      "Epoch 245/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.3556 - accuracy: 0.8364 - val_loss: 0.4721 - val_accuracy: 0.8000\n",
      "Epoch 246/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3555 - accuracy: 0.8364 - val_loss: 0.4740 - val_accuracy: 0.8000\n",
      "Epoch 247/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.3553 - accuracy: 0.8364 - val_loss: 0.4752 - val_accuracy: 0.8000\n",
      "Epoch 248/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3548 - accuracy: 0.8364 - val_loss: 0.4752 - val_accuracy: 0.8000\n",
      "Epoch 249/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.3543 - accuracy: 0.8364 - val_loss: 0.4752 - val_accuracy: 0.8000\n",
      "Epoch 250/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.3543 - accuracy: 0.8455 - val_loss: 0.4737 - val_accuracy: 0.8000\n",
      "Epoch 251/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3540 - accuracy: 0.8455 - val_loss: 0.4743 - val_accuracy: 0.8000\n",
      "Epoch 252/500\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.3532 - accuracy: 0.8455 - val_loss: 0.4732 - val_accuracy: 0.8000\n",
      "Epoch 253/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.3528 - accuracy: 0.8455 - val_loss: 0.4701 - val_accuracy: 0.7909\n",
      "Epoch 254/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3521 - accuracy: 0.8364 - val_loss: 0.4683 - val_accuracy: 0.8000\n",
      "Epoch 255/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.3517 - accuracy: 0.8364 - val_loss: 0.4681 - val_accuracy: 0.8000\n",
      "Epoch 256/500\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.3520 - accuracy: 0.8364 - val_loss: 0.4670 - val_accuracy: 0.8000\n",
      "Epoch 257/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.3512 - accuracy: 0.8364 - val_loss: 0.4666 - val_accuracy: 0.8000\n",
      "Epoch 258/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.3506 - accuracy: 0.8364 - val_loss: 0.4675 - val_accuracy: 0.8000\n",
      "Epoch 259/500\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.3510 - accuracy: 0.8364 - val_loss: 0.4685 - val_accuracy: 0.8000\n",
      "Epoch 260/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.3502 - accuracy: 0.8364 - val_loss: 0.4674 - val_accuracy: 0.8000\n",
      "Epoch 261/500\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.3500 - accuracy: 0.8364 - val_loss: 0.4677 - val_accuracy: 0.8000\n",
      "Epoch 262/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.3497 - accuracy: 0.8364 - val_loss: 0.4672 - val_accuracy: 0.8000\n",
      "Epoch 263/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.3491 - accuracy: 0.8364 - val_loss: 0.4676 - val_accuracy: 0.8000\n",
      "Epoch 264/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3491 - accuracy: 0.8455 - val_loss: 0.4689 - val_accuracy: 0.7909\n",
      "Epoch 265/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.3489 - accuracy: 0.8455 - val_loss: 0.4696 - val_accuracy: 0.7818\n",
      "Epoch 266/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.3485 - accuracy: 0.8455 - val_loss: 0.4700 - val_accuracy: 0.7818\n",
      "Epoch 267/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.3484 - accuracy: 0.8455 - val_loss: 0.4697 - val_accuracy: 0.7909\n",
      "Epoch 268/500\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.3483 - accuracy: 0.8455 - val_loss: 0.4677 - val_accuracy: 0.8000\n",
      "Epoch 269/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.3474 - accuracy: 0.8455 - val_loss: 0.4663 - val_accuracy: 0.8000\n",
      "Epoch 270/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3469 - accuracy: 0.8455 - val_loss: 0.4661 - val_accuracy: 0.8000\n",
      "Epoch 271/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.3468 - accuracy: 0.8455 - val_loss: 0.4649 - val_accuracy: 0.8000\n",
      "Epoch 272/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.3465 - accuracy: 0.8364 - val_loss: 0.4637 - val_accuracy: 0.8000\n",
      "Epoch 273/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.3462 - accuracy: 0.8364 - val_loss: 0.4626 - val_accuracy: 0.8000\n",
      "Epoch 274/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.3460 - accuracy: 0.8364 - val_loss: 0.4628 - val_accuracy: 0.8000\n",
      "Epoch 275/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3455 - accuracy: 0.8364 - val_loss: 0.4616 - val_accuracy: 0.8000\n",
      "Epoch 276/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.3451 - accuracy: 0.8364 - val_loss: 0.4619 - val_accuracy: 0.8000\n",
      "Epoch 277/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3451 - accuracy: 0.8364 - val_loss: 0.4633 - val_accuracy: 0.8000\n",
      "Epoch 278/500\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.3447 - accuracy: 0.8364 - val_loss: 0.4645 - val_accuracy: 0.8000\n",
      "Epoch 279/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.3455 - accuracy: 0.8364 - val_loss: 0.4682 - val_accuracy: 0.8000\n",
      "Epoch 280/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.3444 - accuracy: 0.8455 - val_loss: 0.4669 - val_accuracy: 0.8000\n",
      "Epoch 281/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.3439 - accuracy: 0.8455 - val_loss: 0.4678 - val_accuracy: 0.8000\n",
      "Epoch 282/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.3434 - accuracy: 0.8455 - val_loss: 0.4675 - val_accuracy: 0.8000\n",
      "Epoch 283/500\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.3434 - accuracy: 0.8455 - val_loss: 0.4690 - val_accuracy: 0.8000\n",
      "Epoch 284/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3432 - accuracy: 0.8545 - val_loss: 0.4698 - val_accuracy: 0.8000\n",
      "Epoch 285/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.3429 - accuracy: 0.8545 - val_loss: 0.4700 - val_accuracy: 0.8000\n",
      "Epoch 286/500\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.3429 - accuracy: 0.8545 - val_loss: 0.4692 - val_accuracy: 0.8000\n",
      "Epoch 287/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.3423 - accuracy: 0.8455 - val_loss: 0.4691 - val_accuracy: 0.8000\n",
      "Epoch 288/500\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.3436 - accuracy: 0.8455 - val_loss: 0.4666 - val_accuracy: 0.8091\n",
      "Epoch 289/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3420 - accuracy: 0.8455 - val_loss: 0.4673 - val_accuracy: 0.8091\n",
      "Epoch 290/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.3418 - accuracy: 0.8455 - val_loss: 0.4686 - val_accuracy: 0.8000\n",
      "Epoch 291/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.3415 - accuracy: 0.8455 - val_loss: 0.4705 - val_accuracy: 0.8000\n",
      "Epoch 292/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3412 - accuracy: 0.8545 - val_loss: 0.4700 - val_accuracy: 0.8000\n",
      "Epoch 293/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.3410 - accuracy: 0.8545 - val_loss: 0.4692 - val_accuracy: 0.8000\n",
      "Epoch 294/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.3406 - accuracy: 0.8455 - val_loss: 0.4673 - val_accuracy: 0.8000\n",
      "Epoch 295/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.3402 - accuracy: 0.8455 - val_loss: 0.4661 - val_accuracy: 0.8000\n",
      "Epoch 296/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.3403 - accuracy: 0.8455 - val_loss: 0.4655 - val_accuracy: 0.8000\n",
      "Epoch 297/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.3400 - accuracy: 0.8455 - val_loss: 0.4654 - val_accuracy: 0.8000\n",
      "Epoch 298/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.3397 - accuracy: 0.8455 - val_loss: 0.4648 - val_accuracy: 0.8000\n",
      "Epoch 299/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.3393 - accuracy: 0.8455 - val_loss: 0.4644 - val_accuracy: 0.8000\n",
      "Epoch 300/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3392 - accuracy: 0.8455 - val_loss: 0.4649 - val_accuracy: 0.8000\n",
      "Epoch 301/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3389 - accuracy: 0.8455 - val_loss: 0.4650 - val_accuracy: 0.8000\n",
      "Epoch 302/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.3390 - accuracy: 0.8455 - val_loss: 0.4647 - val_accuracy: 0.8000\n",
      "Epoch 303/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3385 - accuracy: 0.8455 - val_loss: 0.4645 - val_accuracy: 0.8000\n",
      "Epoch 304/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.3385 - accuracy: 0.8455 - val_loss: 0.4641 - val_accuracy: 0.8000\n",
      "Epoch 305/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.3380 - accuracy: 0.8455 - val_loss: 0.4637 - val_accuracy: 0.8000\n",
      "Epoch 306/500\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.3379 - accuracy: 0.8455 - val_loss: 0.4629 - val_accuracy: 0.8000\n",
      "Epoch 307/500\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.3375 - accuracy: 0.8455 - val_loss: 0.4635 - val_accuracy: 0.8000\n",
      "Epoch 308/500\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.3375 - accuracy: 0.8455 - val_loss: 0.4648 - val_accuracy: 0.8000\n",
      "Epoch 309/500\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.3373 - accuracy: 0.8455 - val_loss: 0.4649 - val_accuracy: 0.8000\n",
      "Epoch 310/500\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.3380 - accuracy: 0.8455 - val_loss: 0.4667 - val_accuracy: 0.8000\n",
      "Epoch 311/500\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.3368 - accuracy: 0.8545 - val_loss: 0.4650 - val_accuracy: 0.8000\n",
      "Epoch 312/500\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.3365 - accuracy: 0.8455 - val_loss: 0.4630 - val_accuracy: 0.8000\n",
      "Epoch 313/500\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.3363 - accuracy: 0.8455 - val_loss: 0.4607 - val_accuracy: 0.8000\n",
      "Epoch 314/500\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.3363 - accuracy: 0.8455 - val_loss: 0.4609 - val_accuracy: 0.8000\n",
      "Epoch 315/500\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.3370 - accuracy: 0.8455 - val_loss: 0.4609 - val_accuracy: 0.8000\n",
      "Epoch 316/500\n",
      "4/4 [==============================] - 0s 29ms/step - loss: 0.3365 - accuracy: 0.8455 - val_loss: 0.4621 - val_accuracy: 0.8000\n",
      "Epoch 317/500\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.3362 - accuracy: 0.8455 - val_loss: 0.4638 - val_accuracy: 0.8000\n",
      "Epoch 318/500\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.3354 - accuracy: 0.8455 - val_loss: 0.4642 - val_accuracy: 0.8000\n",
      "Epoch 319/500\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.3352 - accuracy: 0.8455 - val_loss: 0.4646 - val_accuracy: 0.8000\n",
      "Epoch 320/500\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.3350 - accuracy: 0.8455 - val_loss: 0.4668 - val_accuracy: 0.8000\n",
      "Epoch 321/500\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.3353 - accuracy: 0.8545 - val_loss: 0.4677 - val_accuracy: 0.7909\n",
      "Epoch 322/500\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.3354 - accuracy: 0.8455 - val_loss: 0.4658 - val_accuracy: 0.8000\n",
      "Epoch 323/500\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.3345 - accuracy: 0.8455 - val_loss: 0.4658 - val_accuracy: 0.8000\n",
      "Epoch 324/500\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.3349 - accuracy: 0.8545 - val_loss: 0.4662 - val_accuracy: 0.7909\n",
      "Epoch 325/500\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.3342 - accuracy: 0.8455 - val_loss: 0.4660 - val_accuracy: 0.8000\n",
      "Epoch 326/500\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.3346 - accuracy: 0.8455 - val_loss: 0.4649 - val_accuracy: 0.8000\n",
      "Epoch 327/500\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.3342 - accuracy: 0.8455 - val_loss: 0.4641 - val_accuracy: 0.8000\n",
      "Epoch 328/500\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.3337 - accuracy: 0.8455 - val_loss: 0.4653 - val_accuracy: 0.8000\n",
      "Epoch 329/500\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.3334 - accuracy: 0.8455 - val_loss: 0.4662 - val_accuracy: 0.8000\n",
      "Epoch 330/500\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.3333 - accuracy: 0.8455 - val_loss: 0.4676 - val_accuracy: 0.8000\n",
      "Epoch 331/500\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.3331 - accuracy: 0.8455 - val_loss: 0.4675 - val_accuracy: 0.8000\n",
      "Epoch 332/500\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.3329 - accuracy: 0.8455 - val_loss: 0.4681 - val_accuracy: 0.8000\n",
      "Epoch 333/500\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.3329 - accuracy: 0.8455 - val_loss: 0.4668 - val_accuracy: 0.8000\n",
      "Epoch 334/500\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.3323 - accuracy: 0.8455 - val_loss: 0.4663 - val_accuracy: 0.8091\n",
      "Epoch 335/500\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.3322 - accuracy: 0.8455 - val_loss: 0.4664 - val_accuracy: 0.8091\n",
      "Epoch 336/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.3321 - accuracy: 0.8455 - val_loss: 0.4655 - val_accuracy: 0.8000\n",
      "Epoch 337/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.3325 - accuracy: 0.8455 - val_loss: 0.4647 - val_accuracy: 0.8000\n",
      "Epoch 338/500\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.3320 - accuracy: 0.8455 - val_loss: 0.4652 - val_accuracy: 0.8000\n",
      "Epoch 339/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.3317 - accuracy: 0.8455 - val_loss: 0.4662 - val_accuracy: 0.8000\n",
      "Epoch 340/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.3314 - accuracy: 0.8455 - val_loss: 0.4669 - val_accuracy: 0.8000\n",
      "Epoch 341/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.3317 - accuracy: 0.8455 - val_loss: 0.4681 - val_accuracy: 0.8000\n",
      "Epoch 342/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.3313 - accuracy: 0.8455 - val_loss: 0.4667 - val_accuracy: 0.8000\n",
      "Epoch 343/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3309 - accuracy: 0.8455 - val_loss: 0.4660 - val_accuracy: 0.8000\n",
      "Epoch 344/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3307 - accuracy: 0.8455 - val_loss: 0.4656 - val_accuracy: 0.8000\n",
      "Epoch 345/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3305 - accuracy: 0.8455 - val_loss: 0.4655 - val_accuracy: 0.8000\n",
      "Epoch 346/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.3307 - accuracy: 0.8455 - val_loss: 0.4662 - val_accuracy: 0.8000\n",
      "Epoch 347/500\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.3306 - accuracy: 0.8455 - val_loss: 0.4641 - val_accuracy: 0.8000\n",
      "Epoch 348/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.3303 - accuracy: 0.8455 - val_loss: 0.4632 - val_accuracy: 0.8000\n",
      "Epoch 349/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3311 - accuracy: 0.8455 - val_loss: 0.4623 - val_accuracy: 0.8000\n",
      "Epoch 350/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.3304 - accuracy: 0.8455 - val_loss: 0.4636 - val_accuracy: 0.8000\n",
      "Epoch 351/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.3300 - accuracy: 0.8455 - val_loss: 0.4654 - val_accuracy: 0.8000\n",
      "Epoch 352/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3305 - accuracy: 0.8455 - val_loss: 0.4676 - val_accuracy: 0.8000\n",
      "Epoch 353/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.3298 - accuracy: 0.8455 - val_loss: 0.4669 - val_accuracy: 0.8000\n",
      "Epoch 354/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.3292 - accuracy: 0.8455 - val_loss: 0.4660 - val_accuracy: 0.8000\n",
      "Epoch 355/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.3291 - accuracy: 0.8455 - val_loss: 0.4663 - val_accuracy: 0.8000\n",
      "Epoch 356/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.3288 - accuracy: 0.8455 - val_loss: 0.4661 - val_accuracy: 0.8000\n",
      "Epoch 357/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3291 - accuracy: 0.8455 - val_loss: 0.4649 - val_accuracy: 0.8000\n",
      "Epoch 358/500\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.3291 - accuracy: 0.8455 - val_loss: 0.4638 - val_accuracy: 0.8000\n",
      "Epoch 359/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3286 - accuracy: 0.8455 - val_loss: 0.4648 - val_accuracy: 0.8000\n",
      "Epoch 360/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3282 - accuracy: 0.8455 - val_loss: 0.4663 - val_accuracy: 0.8000\n",
      "Epoch 361/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.3284 - accuracy: 0.8455 - val_loss: 0.4685 - val_accuracy: 0.8000\n",
      "Epoch 362/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.3287 - accuracy: 0.8455 - val_loss: 0.4700 - val_accuracy: 0.8091\n",
      "Epoch 363/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3279 - accuracy: 0.8455 - val_loss: 0.4692 - val_accuracy: 0.8091\n",
      "Epoch 364/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3280 - accuracy: 0.8455 - val_loss: 0.4673 - val_accuracy: 0.8091\n",
      "Epoch 365/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3277 - accuracy: 0.8455 - val_loss: 0.4675 - val_accuracy: 0.8091\n",
      "Epoch 366/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.3276 - accuracy: 0.8455 - val_loss: 0.4658 - val_accuracy: 0.8091\n",
      "Epoch 367/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3271 - accuracy: 0.8455 - val_loss: 0.4663 - val_accuracy: 0.8091\n",
      "Epoch 368/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.3272 - accuracy: 0.8455 - val_loss: 0.4674 - val_accuracy: 0.8091\n",
      "Epoch 369/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3272 - accuracy: 0.8455 - val_loss: 0.4689 - val_accuracy: 0.8091\n",
      "Epoch 370/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3269 - accuracy: 0.8455 - val_loss: 0.4710 - val_accuracy: 0.8091\n",
      "Epoch 371/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.3270 - accuracy: 0.8455 - val_loss: 0.4729 - val_accuracy: 0.8000\n",
      "Epoch 372/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.3268 - accuracy: 0.8455 - val_loss: 0.4739 - val_accuracy: 0.7909\n",
      "Epoch 373/500\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.3266 - accuracy: 0.8455 - val_loss: 0.4730 - val_accuracy: 0.8091\n",
      "Epoch 374/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3277 - accuracy: 0.8455 - val_loss: 0.4752 - val_accuracy: 0.8000\n",
      "Epoch 375/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3266 - accuracy: 0.8545 - val_loss: 0.4737 - val_accuracy: 0.8000\n",
      "Epoch 376/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.3261 - accuracy: 0.8455 - val_loss: 0.4709 - val_accuracy: 0.8091\n",
      "Epoch 377/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.3260 - accuracy: 0.8455 - val_loss: 0.4686 - val_accuracy: 0.8091\n",
      "Epoch 378/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.3255 - accuracy: 0.8455 - val_loss: 0.4680 - val_accuracy: 0.8091\n",
      "Epoch 379/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.3256 - accuracy: 0.8455 - val_loss: 0.4674 - val_accuracy: 0.8091\n",
      "Epoch 380/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.3256 - accuracy: 0.8455 - val_loss: 0.4675 - val_accuracy: 0.8091\n",
      "Epoch 381/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.3257 - accuracy: 0.8455 - val_loss: 0.4676 - val_accuracy: 0.8091\n",
      "Epoch 382/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.3255 - accuracy: 0.8455 - val_loss: 0.4669 - val_accuracy: 0.8091\n",
      "Epoch 383/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.3255 - accuracy: 0.8455 - val_loss: 0.4681 - val_accuracy: 0.8091\n",
      "Epoch 384/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.3251 - accuracy: 0.8455 - val_loss: 0.4690 - val_accuracy: 0.8091\n",
      "Epoch 385/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.3250 - accuracy: 0.8455 - val_loss: 0.4711 - val_accuracy: 0.8091\n",
      "Epoch 386/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.3249 - accuracy: 0.8455 - val_loss: 0.4726 - val_accuracy: 0.8091\n",
      "Epoch 387/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.3247 - accuracy: 0.8455 - val_loss: 0.4735 - val_accuracy: 0.8091\n",
      "Epoch 388/500\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.3243 - accuracy: 0.8455 - val_loss: 0.4722 - val_accuracy: 0.8091\n",
      "Epoch 389/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.3242 - accuracy: 0.8455 - val_loss: 0.4716 - val_accuracy: 0.8091\n",
      "Epoch 390/500\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.3247 - accuracy: 0.8455 - val_loss: 0.4696 - val_accuracy: 0.8091\n",
      "Epoch 391/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3246 - accuracy: 0.8455 - val_loss: 0.4698 - val_accuracy: 0.8091\n",
      "Epoch 392/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3240 - accuracy: 0.8455 - val_loss: 0.4687 - val_accuracy: 0.8091\n",
      "Epoch 393/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.3243 - accuracy: 0.8455 - val_loss: 0.4671 - val_accuracy: 0.8091\n",
      "Epoch 394/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.3238 - accuracy: 0.8455 - val_loss: 0.4672 - val_accuracy: 0.8091\n",
      "Epoch 395/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3238 - accuracy: 0.8455 - val_loss: 0.4667 - val_accuracy: 0.8091\n",
      "Epoch 396/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3238 - accuracy: 0.8455 - val_loss: 0.4664 - val_accuracy: 0.8091\n",
      "Epoch 397/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.3234 - accuracy: 0.8455 - val_loss: 0.4662 - val_accuracy: 0.8091\n",
      "Epoch 398/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3237 - accuracy: 0.8455 - val_loss: 0.4651 - val_accuracy: 0.8091\n",
      "Epoch 399/500\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.3233 - accuracy: 0.8455 - val_loss: 0.4651 - val_accuracy: 0.8091\n",
      "Epoch 400/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.3238 - accuracy: 0.8455 - val_loss: 0.4659 - val_accuracy: 0.8091\n",
      "Epoch 401/500\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.3234 - accuracy: 0.8455 - val_loss: 0.4676 - val_accuracy: 0.8091\n",
      "Epoch 402/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3229 - accuracy: 0.8455 - val_loss: 0.4700 - val_accuracy: 0.8091\n",
      "Epoch 403/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3226 - accuracy: 0.8455 - val_loss: 0.4709 - val_accuracy: 0.8091\n",
      "Epoch 404/500\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.3228 - accuracy: 0.8455 - val_loss: 0.4718 - val_accuracy: 0.8000\n",
      "Epoch 405/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3229 - accuracy: 0.8455 - val_loss: 0.4740 - val_accuracy: 0.8000\n",
      "Epoch 406/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3224 - accuracy: 0.8455 - val_loss: 0.4746 - val_accuracy: 0.8000\n",
      "Epoch 407/500\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.3227 - accuracy: 0.8455 - val_loss: 0.4737 - val_accuracy: 0.8000\n",
      "Epoch 408/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3224 - accuracy: 0.8455 - val_loss: 0.4743 - val_accuracy: 0.8000\n",
      "Epoch 409/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.3224 - accuracy: 0.8455 - val_loss: 0.4740 - val_accuracy: 0.8000\n",
      "Epoch 410/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3220 - accuracy: 0.8455 - val_loss: 0.4750 - val_accuracy: 0.8000\n",
      "Epoch 411/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3218 - accuracy: 0.8455 - val_loss: 0.4745 - val_accuracy: 0.8091\n",
      "Epoch 412/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3225 - accuracy: 0.8455 - val_loss: 0.4737 - val_accuracy: 0.8091\n",
      "Epoch 413/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.3217 - accuracy: 0.8455 - val_loss: 0.4732 - val_accuracy: 0.8091\n",
      "Epoch 414/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3214 - accuracy: 0.8455 - val_loss: 0.4728 - val_accuracy: 0.8091\n",
      "Epoch 415/500\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.3219 - accuracy: 0.8455 - val_loss: 0.4745 - val_accuracy: 0.8091\n",
      "Epoch 416/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.3212 - accuracy: 0.8455 - val_loss: 0.4734 - val_accuracy: 0.8091\n",
      "Epoch 417/500\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.3213 - accuracy: 0.8455 - val_loss: 0.4732 - val_accuracy: 0.8000\n",
      "Epoch 418/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.3219 - accuracy: 0.8455 - val_loss: 0.4705 - val_accuracy: 0.8091\n",
      "Epoch 419/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3210 - accuracy: 0.8455 - val_loss: 0.4704 - val_accuracy: 0.8091\n",
      "Epoch 420/500\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.3209 - accuracy: 0.8455 - val_loss: 0.4705 - val_accuracy: 0.8091\n",
      "Epoch 421/500\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.3208 - accuracy: 0.8455 - val_loss: 0.4709 - val_accuracy: 0.8091\n",
      "Epoch 422/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3219 - accuracy: 0.8455 - val_loss: 0.4706 - val_accuracy: 0.8091\n",
      "Epoch 423/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.3205 - accuracy: 0.8455 - val_loss: 0.4738 - val_accuracy: 0.8000\n",
      "Epoch 424/500\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.3210 - accuracy: 0.8455 - val_loss: 0.4748 - val_accuracy: 0.8000\n",
      "Epoch 425/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3205 - accuracy: 0.8545 - val_loss: 0.4733 - val_accuracy: 0.8000\n",
      "Epoch 426/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.3206 - accuracy: 0.8455 - val_loss: 0.4721 - val_accuracy: 0.8000\n",
      "Epoch 427/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.3203 - accuracy: 0.8455 - val_loss: 0.4718 - val_accuracy: 0.8091\n",
      "Epoch 428/500\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.3202 - accuracy: 0.8455 - val_loss: 0.4713 - val_accuracy: 0.8091\n",
      "Epoch 429/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3203 - accuracy: 0.8455 - val_loss: 0.4715 - val_accuracy: 0.8091\n",
      "Epoch 430/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3195 - accuracy: 0.8455 - val_loss: 0.4730 - val_accuracy: 0.8091\n",
      "Epoch 431/500\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.3194 - accuracy: 0.8455 - val_loss: 0.4751 - val_accuracy: 0.8000\n",
      "Epoch 432/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3199 - accuracy: 0.8455 - val_loss: 0.4775 - val_accuracy: 0.8000\n",
      "Epoch 433/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.3198 - accuracy: 0.8455 - val_loss: 0.4780 - val_accuracy: 0.8000\n",
      "Epoch 434/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3197 - accuracy: 0.8455 - val_loss: 0.4758 - val_accuracy: 0.8000\n",
      "Epoch 435/500\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.3201 - accuracy: 0.8455 - val_loss: 0.4735 - val_accuracy: 0.8091\n",
      "Epoch 436/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.3193 - accuracy: 0.8455 - val_loss: 0.4732 - val_accuracy: 0.8091\n",
      "Epoch 437/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.3191 - accuracy: 0.8455 - val_loss: 0.4716 - val_accuracy: 0.8091\n",
      "Epoch 438/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3190 - accuracy: 0.8455 - val_loss: 0.4708 - val_accuracy: 0.8091\n",
      "Epoch 439/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.3193 - accuracy: 0.8455 - val_loss: 0.4706 - val_accuracy: 0.8091\n",
      "Epoch 440/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3188 - accuracy: 0.8455 - val_loss: 0.4709 - val_accuracy: 0.8091\n",
      "Epoch 441/500\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.3195 - accuracy: 0.8455 - val_loss: 0.4721 - val_accuracy: 0.8091\n",
      "Epoch 442/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.3186 - accuracy: 0.8455 - val_loss: 0.4734 - val_accuracy: 0.8091\n",
      "Epoch 443/500\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.3184 - accuracy: 0.8455 - val_loss: 0.4736 - val_accuracy: 0.8091\n",
      "Epoch 444/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3193 - accuracy: 0.8455 - val_loss: 0.4740 - val_accuracy: 0.8091\n",
      "Epoch 445/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.3189 - accuracy: 0.8545 - val_loss: 0.4729 - val_accuracy: 0.8091\n",
      "Epoch 446/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3194 - accuracy: 0.8545 - val_loss: 0.4741 - val_accuracy: 0.8091\n",
      "Epoch 447/500\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.3183 - accuracy: 0.8455 - val_loss: 0.4733 - val_accuracy: 0.8091\n",
      "Epoch 448/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3184 - accuracy: 0.8455 - val_loss: 0.4738 - val_accuracy: 0.8091\n",
      "Epoch 449/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3183 - accuracy: 0.8455 - val_loss: 0.4744 - val_accuracy: 0.8091\n",
      "Epoch 450/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3181 - accuracy: 0.8455 - val_loss: 0.4783 - val_accuracy: 0.8091\n",
      "Epoch 451/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.3179 - accuracy: 0.8545 - val_loss: 0.4799 - val_accuracy: 0.8000\n",
      "Epoch 452/500\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.3179 - accuracy: 0.8545 - val_loss: 0.4802 - val_accuracy: 0.8000\n",
      "Epoch 453/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.3177 - accuracy: 0.8545 - val_loss: 0.4803 - val_accuracy: 0.7818\n",
      "Epoch 454/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.3180 - accuracy: 0.8545 - val_loss: 0.4798 - val_accuracy: 0.7909\n",
      "Epoch 455/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.3176 - accuracy: 0.8545 - val_loss: 0.4806 - val_accuracy: 0.7818\n",
      "Epoch 456/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.3176 - accuracy: 0.8545 - val_loss: 0.4801 - val_accuracy: 0.7909\n",
      "Epoch 457/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.3178 - accuracy: 0.8545 - val_loss: 0.4790 - val_accuracy: 0.8091\n",
      "Epoch 458/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3175 - accuracy: 0.8545 - val_loss: 0.4795 - val_accuracy: 0.8091\n",
      "Epoch 459/500\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.3185 - accuracy: 0.8545 - val_loss: 0.4824 - val_accuracy: 0.7818\n",
      "Epoch 460/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.3173 - accuracy: 0.8545 - val_loss: 0.4809 - val_accuracy: 0.8091\n",
      "Epoch 461/500\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.3173 - accuracy: 0.8545 - val_loss: 0.4793 - val_accuracy: 0.8091\n",
      "Epoch 462/500\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.3171 - accuracy: 0.8545 - val_loss: 0.4790 - val_accuracy: 0.8091\n",
      "Epoch 463/500\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.3173 - accuracy: 0.8545 - val_loss: 0.4799 - val_accuracy: 0.8091\n",
      "Epoch 464/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3167 - accuracy: 0.8545 - val_loss: 0.4817 - val_accuracy: 0.8091\n",
      "Epoch 465/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3173 - accuracy: 0.8545 - val_loss: 0.4832 - val_accuracy: 0.8000\n",
      "Epoch 466/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.3185 - accuracy: 0.8636 - val_loss: 0.4848 - val_accuracy: 0.7909\n",
      "Epoch 467/500\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.3178 - accuracy: 0.8636 - val_loss: 0.4845 - val_accuracy: 0.7818\n",
      "Epoch 468/500\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.3181 - accuracy: 0.8545 - val_loss: 0.4826 - val_accuracy: 0.8000\n",
      "Epoch 469/500\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.3170 - accuracy: 0.8545 - val_loss: 0.4819 - val_accuracy: 0.8000\n",
      "Epoch 470/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3172 - accuracy: 0.8545 - val_loss: 0.4791 - val_accuracy: 0.8091\n",
      "Epoch 471/500\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.3169 - accuracy: 0.8545 - val_loss: 0.4769 - val_accuracy: 0.8091\n",
      "Epoch 472/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.3168 - accuracy: 0.8455 - val_loss: 0.4763 - val_accuracy: 0.8091\n",
      "Epoch 473/500\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.3161 - accuracy: 0.8455 - val_loss: 0.4750 - val_accuracy: 0.8091\n",
      "Epoch 474/500\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.3166 - accuracy: 0.8455 - val_loss: 0.4741 - val_accuracy: 0.8091\n",
      "Epoch 475/500\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.3162 - accuracy: 0.8455 - val_loss: 0.4741 - val_accuracy: 0.8091\n",
      "Epoch 476/500\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.3161 - accuracy: 0.8455 - val_loss: 0.4738 - val_accuracy: 0.8091\n",
      "Epoch 477/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3159 - accuracy: 0.8455 - val_loss: 0.4742 - val_accuracy: 0.8091\n",
      "Epoch 478/500\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.3159 - accuracy: 0.8455 - val_loss: 0.4739 - val_accuracy: 0.8091\n",
      "Epoch 479/500\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.3164 - accuracy: 0.8455 - val_loss: 0.4749 - val_accuracy: 0.8091\n",
      "Epoch 480/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.3158 - accuracy: 0.8455 - val_loss: 0.4739 - val_accuracy: 0.8091\n",
      "Epoch 481/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3162 - accuracy: 0.8455 - val_loss: 0.4721 - val_accuracy: 0.8091\n",
      "Epoch 482/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3160 - accuracy: 0.8455 - val_loss: 0.4727 - val_accuracy: 0.8091\n",
      "Epoch 483/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3159 - accuracy: 0.8455 - val_loss: 0.4724 - val_accuracy: 0.8091\n",
      "Epoch 484/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3156 - accuracy: 0.8455 - val_loss: 0.4729 - val_accuracy: 0.8091\n",
      "Epoch 485/500\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.3157 - accuracy: 0.8455 - val_loss: 0.4743 - val_accuracy: 0.8091\n",
      "Epoch 486/500\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.3156 - accuracy: 0.8455 - val_loss: 0.4753 - val_accuracy: 0.8091\n",
      "Epoch 487/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.3152 - accuracy: 0.8455 - val_loss: 0.4754 - val_accuracy: 0.8091\n",
      "Epoch 488/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.3151 - accuracy: 0.8455 - val_loss: 0.4744 - val_accuracy: 0.8091\n",
      "Epoch 489/500\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.3154 - accuracy: 0.8455 - val_loss: 0.4730 - val_accuracy: 0.8182\n",
      "Epoch 490/500\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.3157 - accuracy: 0.8545 - val_loss: 0.4731 - val_accuracy: 0.8182\n",
      "Epoch 491/500\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.3158 - accuracy: 0.8545 - val_loss: 0.4733 - val_accuracy: 0.8182\n",
      "Epoch 492/500\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.3153 - accuracy: 0.8636 - val_loss: 0.4754 - val_accuracy: 0.8091\n",
      "Epoch 493/500\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.3150 - accuracy: 0.8545 - val_loss: 0.4772 - val_accuracy: 0.8091\n",
      "Epoch 494/500\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.3149 - accuracy: 0.8545 - val_loss: 0.4792 - val_accuracy: 0.8000\n",
      "Epoch 495/500\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.3151 - accuracy: 0.8545 - val_loss: 0.4806 - val_accuracy: 0.8000\n",
      "Epoch 496/500\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.3146 - accuracy: 0.8545 - val_loss: 0.4810 - val_accuracy: 0.8000\n",
      "Epoch 497/500\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.3148 - accuracy: 0.8545 - val_loss: 0.4803 - val_accuracy: 0.8000\n",
      "Epoch 498/500\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.3148 - accuracy: 0.8545 - val_loss: 0.4805 - val_accuracy: 0.8000\n",
      "Epoch 499/500\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.3147 - accuracy: 0.8545 - val_loss: 0.4811 - val_accuracy: 0.8000\n",
      "Epoch 500/500\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.3147 - accuracy: 0.8545 - val_loss: 0.4819 - val_accuracy: 0.7909\n"
     ]
    }
   ],
   "source": [
    "\n",
    "inputs = Input(shape=(2,))\n",
    "hidden_layer = Dense(25, activation='relu')(inputs)\n",
    "outputs = Dense(3, activation='softmax')(hidden_layer)\n",
    "\n",
    "nn_model = Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "nn_model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "history = nn_model.fit(trainX, trainy_cat, epochs=500, validation_data=(valX, valy_cat))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "STEsmSmB84yO"
   },
   "source": [
    "we now check the performance of the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 448
    },
    "id": "sk7qiXsf8_IZ",
    "outputId": "7c13d49a-dfae-43a7-ab8a-d98413ee5b6f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 0.855, Val: 0.791, Test: 0.803\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "_, train_acc = nn_model.evaluate(trainX, trainy_cat, verbose=0)\n",
    "_, val_acc = nn_model.evaluate(valX, valy_cat, verbose=0)\n",
    "_, test_acc = nn_model.evaluate(testX, testy_cat, verbose=0)\n",
    "print('Train: %.3f, Val: %.3f, Test: %.3f' % (train_acc, val_acc, test_acc))\n",
    "pyplot.plot(history.history['accuracy'], label='train')\n",
    "pyplot.plot(history.history['val_accuracy'], label='validation')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4SBF6XL96O5R"
   },
   "source": [
    "**Exercise 2.2**\n",
    "\n",
    "Initialise a decision tree (use *dt_model* as variable name) using random_state=123, setting maximum depth to 2 and using the default splitting criterion.\n",
    "\n",
    "Train *dt_model* on trainX."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 75
    },
    "id": "2Qy1lc2vTQ4H",
    "outputId": "74e409d2-c15e-4a93-936a-c442031290f0"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier(max_depth=2, random_state=123)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(max_depth=2, random_state=123)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier(max_depth=2, random_state=123)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add your code here\n",
    "\n",
    "dt_model = DecisionTreeClassifier(random_state=123, max_depth=2)\n",
    "\n",
    "dt_model.fit(trainX, trainy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H6BFqUNq6w0Q"
   },
   "source": [
    "We check the accuracy on train, validation and test; we extract the probabilities for each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "khLZZVCaZmmu",
    "outputId": "f7d18be8-3d31-46e5-af0c-f4cae5d6bac7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 0.836, Val: 0.709, Test: 0.773\n",
      "4/4 [==============================] - 0s 7ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "28/28 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "print('Train: %.3f, Val: %.3f, Test: %.3f' % (dt_model.score(trainX, trainy), dt_model.score(valX, valy), dt_model.score(testX, testy)))\n",
    "nn_scores_train, nn_scores_val, nn_scores_test = (nn_model.predict(trainX), nn_model.predict(valX), nn_model.predict(testX))\n",
    "dt_scores_train, dt_scores_val, dt_scores_test = (dt_model.predict_proba(trainX), dt_model.predict_proba(valX), dt_model.predict_proba(testX))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TweXgCtBHDNW"
   },
   "source": [
    " **Exercise 2.3**\n",
    "\n",
    " Let's consider a $\\phi()$ function that maps an example of the dataset into 6 features:\n",
    "\n",
    "1.   the probability of the example to belong to each class by the Neural Network model (first 3 features)\n",
    "2.   the probability of the example to belong to each class by the Decision Tree (latest 3 features)\n",
    "\n",
    "Let's create the corresponding training, validation and test datasets.\n",
    "For the variable names, add the prefix \"stacked_\", for example stacked_X_train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SXgcnhLKHJSr",
    "outputId": "d2e9bb43-9415-4c73-d14a-bdad07452e90"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "28/28 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "# Add your code here\n",
    "# stacked_X_train =\n",
    "# stacked_X_val =\n",
    "# stacked_X_test =\n",
    "\n",
    "# For neural network model\n",
    "nn_train_probs = model.predict(trainX)\n",
    "nn_val_probs = model.predict(valX)\n",
    "nn_test_probs = model.predict(testX)\n",
    "\n",
    "# For decision tree model\n",
    "dt_train_probs = dt_model.predict_proba(trainX)\n",
    "dt_val_probs = dt_model.predict_proba(valX)\n",
    "dt_test_probs = dt_model.predict_proba(testX)\n",
    "\n",
    "stacked_X_train = np.hstack((nn_train_probs, dt_train_probs))\n",
    "stacked_X_val = np.hstack((nn_val_probs, dt_val_probs))\n",
    "stacked_X_test = np.hstack((nn_test_probs, dt_test_probs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "13W6-lX9HP6F",
    "outputId": "87d7c232-ca04-47fa-fd12-55cd77933453"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(110, 6) (110, 6) (880, 6)\n"
     ]
    }
   ],
   "source": [
    "print(stacked_X_train.shape, stacked_X_val.shape, stacked_X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K6nxlP0XeWLw"
   },
   "source": [
    "**Exercise 2.4** We now train a Logistic Regression classifier on this new data we just created. Specifically, we set the maximum iterations to 500 and fit_intercept=True. We select the best value of the C parameter, among 0.001, 0.01, 0.1, 1, 10, 100, 1000, with respect to its accuracy on the validation set.\n",
    "Finally, we print the accuracy of the best model (trained on the training set only) on the validation and test sets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TDFnIM7_UJFW",
    "outputId": "92336863-7568-4746-89a9-aca9defcb0f3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best C : 1000\n",
      "Validation Accuracy: 0.8\n",
      "Training Accuracy: 0.8363636363636363\n",
      "Test Accuracy: 0.8011363636363636\n"
     ]
    }
   ],
   "source": [
    "# Add your code here\n",
    "\n",
    "lr_model = LogisticRegression(max_iter=500, fit_intercept=True)\n",
    "\n",
    "C_values = [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "best_val_accuracy = 0\n",
    "best_C = None\n",
    "\n",
    "for C in C_values:\n",
    "    lr_model.C = C\n",
    "    lr_model.fit(stacked_X_train, trainy)\n",
    "    val_accuracy = lr_model.score(stacked_X_val, valy)\n",
    "\n",
    "    if val_accuracy > best_val_accuracy:\n",
    "        best_val_accuracy = val_accuracy\n",
    "        best_C = C\n",
    "\n",
    "lr_model.C = best_C\n",
    "lr_model.fit(stacked_X_train, trainy)\n",
    "\n",
    "train_accuracy = lr_model.score(stacked_X_train, trainy)\n",
    "val_accuracy = lr_model.score(stacked_X_val, valy)\n",
    "test_accuracy = lr_model.score(stacked_X_test, testy)\n",
    "\n",
    "print(\"Best C :\", best_C)\n",
    "print(\"Validation Accuracy:\", val_accuracy)\n",
    "print(\"Training Accuracy:\", train_accuracy)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IXWJIk2VgVxg"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
